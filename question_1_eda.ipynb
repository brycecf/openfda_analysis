{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - API Response EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import country_converter as coco\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "import numpy as np\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "from project_utils.io import load_json_file\n",
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import DistanceMetric, NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bcf4k\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Examining Country Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with examining the country response (since it should be the simplest data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_occur_countries_d = load_json_file('data/all_occur_countries.json')\n",
    "all_occur_countries_df = pd.DataFrame.from_dict(all_occur_countries_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a count query of countries, there should only be one row for a given country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TL    1\n",
       "ML    1\n",
       "AN    1\n",
       "MT    1\n",
       "TH    1\n",
       "     ..\n",
       "BF    1\n",
       "UG    1\n",
       "VC    1\n",
       "CI    1\n",
       "FI    1\n",
       "Name: term, Length: 235, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_occur_countries_df['term'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, the data shows that.  Now, let's map the country codes to country name and retrieve the ISO3 country code for a future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso2_countries = list(all_occur_countries_df['term'].values)\n",
    "cc = coco.CountryConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:YU not found in ISO2\n",
      "WARNING:root:AN not found in ISO2\n",
      "WARNING:root:TP not found in ISO2\n",
      "WARNING:root:FX not found in ISO2\n",
      "WARNING:root:QZ not found in ISO2\n",
      "WARNING:root:YU not found in ISO2\n",
      "WARNING:root:AN not found in ISO2\n",
      "WARNING:root:TP not found in ISO2\n",
      "WARNING:root:FX not found in ISO2\n",
      "WARNING:root:QZ not found in ISO2\n"
     ]
    }
   ],
   "source": [
    "iso3_countries = pd.Series(cc.convert(iso2_countries, to='ISO3')).replace('not found', np.NaN)\n",
    "countries_short_name = pd.Series(cc.convert(iso2_countries, to='short_name')).replace('not found', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 235 entries, 0 to 234\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   term    235 non-null    object\n",
      " 1   count   235 non-null    int64 \n",
      " 2   iso3    230 non-null    object\n",
      " 3   name    230 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 7.5+ KB\n"
     ]
    }
   ],
   "source": [
    "all_occur_countries_df['iso3'] = iso3_countries\n",
    "all_occur_countries_df['name'] = countries_short_name\n",
    "all_occur_countries_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>count</th>\n",
       "      <th>iso3</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>6136862</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GB</td>\n",
       "      <td>298758</td>\n",
       "      <td>GBR</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>260177</td>\n",
       "      <td>CAN</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JP</td>\n",
       "      <td>259359</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR</td>\n",
       "      <td>250505</td>\n",
       "      <td>FRA</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>SX</td>\n",
       "      <td>1</td>\n",
       "      <td>SXM</td>\n",
       "      <td>Sint Maarten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>TV</td>\n",
       "      <td>1</td>\n",
       "      <td>TUV</td>\n",
       "      <td>Tuvalu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>VC</td>\n",
       "      <td>1</td>\n",
       "      <td>VCT</td>\n",
       "      <td>St. Vincent and the Grenadines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>WF</td>\n",
       "      <td>1</td>\n",
       "      <td>WLF</td>\n",
       "      <td>Wallis and Futuna Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>XK</td>\n",
       "      <td>1</td>\n",
       "      <td>XKX</td>\n",
       "      <td>Kosovo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    term    count iso3                            name\n",
       "0     US  6136862  USA                   United States\n",
       "1     GB   298758  GBR                  United Kingdom\n",
       "2     CA   260177  CAN                          Canada\n",
       "3     JP   259359  JPN                           Japan\n",
       "4     FR   250505  FRA                          France\n",
       "..   ...      ...  ...                             ...\n",
       "230   SX        1  SXM                    Sint Maarten\n",
       "231   TV        1  TUV                          Tuvalu\n",
       "232   VC        1  VCT  St. Vincent and the Grenadines\n",
       "233   WF        1  WLF       Wallis and Futuna Islands\n",
       "234   XK        1  XKX                          Kosovo\n",
       "\n",
       "[235 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_occur_countries_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By being able to see the country names, we notice that the data does not fully aggregate countries in terms of sovereignty.  Wallis and Futuna Islands (as well as the Falklands) are counted separately from France and the UK (respectively).  This is not a major concern given the small number of records associated with these entities, but it is good to know.\n",
    "\n",
    "The FDA resources indicate that adverse reaction counts should be suspect due to the underlying processes involved in their collection.  As a consequence of one of those processes, we would also expect to see a likely positive correlation between counts and population sizes. Let's examine that using 2018 data from the World Bank: https://data.worldbank.org/indicator/SP.POP.TOTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>...</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>54211.0</td>\n",
       "      <td>55438.0</td>\n",
       "      <td>56225.0</td>\n",
       "      <td>56695.0</td>\n",
       "      <td>57032.0</td>\n",
       "      <td>57360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>101669.0</td>\n",
       "      <td>102046.0</td>\n",
       "      <td>102560.0</td>\n",
       "      <td>103159.0</td>\n",
       "      <td>103774.0</td>\n",
       "      <td>104341.0</td>\n",
       "      <td>104872.0</td>\n",
       "      <td>105366.0</td>\n",
       "      <td>105845.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>8996973.0</td>\n",
       "      <td>9169410.0</td>\n",
       "      <td>9351441.0</td>\n",
       "      <td>9543205.0</td>\n",
       "      <td>9744781.0</td>\n",
       "      <td>9956320.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29185507.0</td>\n",
       "      <td>30117413.0</td>\n",
       "      <td>31161376.0</td>\n",
       "      <td>32269589.0</td>\n",
       "      <td>33370794.0</td>\n",
       "      <td>34413603.0</td>\n",
       "      <td>35383128.0</td>\n",
       "      <td>36296400.0</td>\n",
       "      <td>37172386.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>5454933.0</td>\n",
       "      <td>5531472.0</td>\n",
       "      <td>5608539.0</td>\n",
       "      <td>5679458.0</td>\n",
       "      <td>5735044.0</td>\n",
       "      <td>5770570.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23356246.0</td>\n",
       "      <td>24220661.0</td>\n",
       "      <td>25107931.0</td>\n",
       "      <td>26015780.0</td>\n",
       "      <td>26941779.0</td>\n",
       "      <td>27884381.0</td>\n",
       "      <td>28842484.0</td>\n",
       "      <td>29816748.0</td>\n",
       "      <td>30809762.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>1608800.0</td>\n",
       "      <td>1659800.0</td>\n",
       "      <td>1711319.0</td>\n",
       "      <td>1762621.0</td>\n",
       "      <td>1814135.0</td>\n",
       "      <td>1864791.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2913021.0</td>\n",
       "      <td>2905195.0</td>\n",
       "      <td>2900401.0</td>\n",
       "      <td>2895092.0</td>\n",
       "      <td>2889104.0</td>\n",
       "      <td>2880703.0</td>\n",
       "      <td>2876101.0</td>\n",
       "      <td>2873457.0</td>\n",
       "      <td>2866376.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>13411.0</td>\n",
       "      <td>14375.0</td>\n",
       "      <td>15370.0</td>\n",
       "      <td>16412.0</td>\n",
       "      <td>17469.0</td>\n",
       "      <td>18549.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84449.0</td>\n",
       "      <td>83747.0</td>\n",
       "      <td>82427.0</td>\n",
       "      <td>80774.0</td>\n",
       "      <td>79213.0</td>\n",
       "      <td>78011.0</td>\n",
       "      <td>77297.0</td>\n",
       "      <td>77001.0</td>\n",
       "      <td>77006.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Kosovo</td>\n",
       "      <td>XKX</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>947000.0</td>\n",
       "      <td>966000.0</td>\n",
       "      <td>994000.0</td>\n",
       "      <td>1022000.0</td>\n",
       "      <td>1050000.0</td>\n",
       "      <td>1078000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1775680.0</td>\n",
       "      <td>1791000.0</td>\n",
       "      <td>1805200.0</td>\n",
       "      <td>1824100.0</td>\n",
       "      <td>1821800.0</td>\n",
       "      <td>1801800.0</td>\n",
       "      <td>1816200.0</td>\n",
       "      <td>1830700.0</td>\n",
       "      <td>1845300.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>YEM</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>5315355.0</td>\n",
       "      <td>5393036.0</td>\n",
       "      <td>5473671.0</td>\n",
       "      <td>5556766.0</td>\n",
       "      <td>5641597.0</td>\n",
       "      <td>5727751.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23154855.0</td>\n",
       "      <td>23807588.0</td>\n",
       "      <td>24473178.0</td>\n",
       "      <td>25147109.0</td>\n",
       "      <td>25823485.0</td>\n",
       "      <td>26497889.0</td>\n",
       "      <td>27168210.0</td>\n",
       "      <td>27834821.0</td>\n",
       "      <td>28498687.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>ZAF</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>17099840.0</td>\n",
       "      <td>17524533.0</td>\n",
       "      <td>17965725.0</td>\n",
       "      <td>18423161.0</td>\n",
       "      <td>18896307.0</td>\n",
       "      <td>19384841.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51216964.0</td>\n",
       "      <td>52004172.0</td>\n",
       "      <td>52834005.0</td>\n",
       "      <td>53689236.0</td>\n",
       "      <td>54545991.0</td>\n",
       "      <td>55386367.0</td>\n",
       "      <td>56203654.0</td>\n",
       "      <td>57000451.0</td>\n",
       "      <td>57779622.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>3070776.0</td>\n",
       "      <td>3164329.0</td>\n",
       "      <td>3260650.0</td>\n",
       "      <td>3360104.0</td>\n",
       "      <td>3463213.0</td>\n",
       "      <td>3570464.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13605984.0</td>\n",
       "      <td>14023193.0</td>\n",
       "      <td>14465121.0</td>\n",
       "      <td>14926504.0</td>\n",
       "      <td>15399753.0</td>\n",
       "      <td>15879361.0</td>\n",
       "      <td>16363507.0</td>\n",
       "      <td>16853688.0</td>\n",
       "      <td>17351822.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>3776681.0</td>\n",
       "      <td>3905034.0</td>\n",
       "      <td>4039201.0</td>\n",
       "      <td>4178726.0</td>\n",
       "      <td>4322861.0</td>\n",
       "      <td>4471177.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12697723.0</td>\n",
       "      <td>12894316.0</td>\n",
       "      <td>13115131.0</td>\n",
       "      <td>13350356.0</td>\n",
       "      <td>13586681.0</td>\n",
       "      <td>13814629.0</td>\n",
       "      <td>14030390.0</td>\n",
       "      <td>14236745.0</td>\n",
       "      <td>14439018.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country Name Country Code     Indicator Name Indicator Code        1960  \\\n",
       "0           Aruba          ABW  Population, total    SP.POP.TOTL     54211.0   \n",
       "1     Afghanistan          AFG  Population, total    SP.POP.TOTL   8996973.0   \n",
       "2          Angola          AGO  Population, total    SP.POP.TOTL   5454933.0   \n",
       "3         Albania          ALB  Population, total    SP.POP.TOTL   1608800.0   \n",
       "4         Andorra          AND  Population, total    SP.POP.TOTL     13411.0   \n",
       "..            ...          ...                ...            ...         ...   \n",
       "259        Kosovo          XKX  Population, total    SP.POP.TOTL    947000.0   \n",
       "260   Yemen, Rep.          YEM  Population, total    SP.POP.TOTL   5315355.0   \n",
       "261  South Africa          ZAF  Population, total    SP.POP.TOTL  17099840.0   \n",
       "262        Zambia          ZMB  Population, total    SP.POP.TOTL   3070776.0   \n",
       "263      Zimbabwe          ZWE  Population, total    SP.POP.TOTL   3776681.0   \n",
       "\n",
       "           1961        1962        1963        1964        1965  ...  \\\n",
       "0       55438.0     56225.0     56695.0     57032.0     57360.0  ...   \n",
       "1     9169410.0   9351441.0   9543205.0   9744781.0   9956320.0  ...   \n",
       "2     5531472.0   5608539.0   5679458.0   5735044.0   5770570.0  ...   \n",
       "3     1659800.0   1711319.0   1762621.0   1814135.0   1864791.0  ...   \n",
       "4       14375.0     15370.0     16412.0     17469.0     18549.0  ...   \n",
       "..          ...         ...         ...         ...         ...  ...   \n",
       "259    966000.0    994000.0   1022000.0   1050000.0   1078000.0  ...   \n",
       "260   5393036.0   5473671.0   5556766.0   5641597.0   5727751.0  ...   \n",
       "261  17524533.0  17965725.0  18423161.0  18896307.0  19384841.0  ...   \n",
       "262   3164329.0   3260650.0   3360104.0   3463213.0   3570464.0  ...   \n",
       "263   3905034.0   4039201.0   4178726.0   4322861.0   4471177.0  ...   \n",
       "\n",
       "           2010        2011        2012        2013        2014        2015  \\\n",
       "0      101669.0    102046.0    102560.0    103159.0    103774.0    104341.0   \n",
       "1    29185507.0  30117413.0  31161376.0  32269589.0  33370794.0  34413603.0   \n",
       "2    23356246.0  24220661.0  25107931.0  26015780.0  26941779.0  27884381.0   \n",
       "3     2913021.0   2905195.0   2900401.0   2895092.0   2889104.0   2880703.0   \n",
       "4       84449.0     83747.0     82427.0     80774.0     79213.0     78011.0   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "259   1775680.0   1791000.0   1805200.0   1824100.0   1821800.0   1801800.0   \n",
       "260  23154855.0  23807588.0  24473178.0  25147109.0  25823485.0  26497889.0   \n",
       "261  51216964.0  52004172.0  52834005.0  53689236.0  54545991.0  55386367.0   \n",
       "262  13605984.0  14023193.0  14465121.0  14926504.0  15399753.0  15879361.0   \n",
       "263  12697723.0  12894316.0  13115131.0  13350356.0  13586681.0  13814629.0   \n",
       "\n",
       "           2016        2017        2018  2019  \n",
       "0      104872.0    105366.0    105845.0   NaN  \n",
       "1    35383128.0  36296400.0  37172386.0   NaN  \n",
       "2    28842484.0  29816748.0  30809762.0   NaN  \n",
       "3     2876101.0   2873457.0   2866376.0   NaN  \n",
       "4       77297.0     77001.0     77006.0   NaN  \n",
       "..          ...         ...         ...   ...  \n",
       "259   1816200.0   1830700.0   1845300.0   NaN  \n",
       "260  27168210.0  27834821.0  28498687.0   NaN  \n",
       "261  56203654.0  57000451.0  57779622.0   NaN  \n",
       "262  16363507.0  16853688.0  17351822.0   NaN  \n",
       "263  14030390.0  14236745.0  14439018.0   NaN  \n",
       "\n",
       "[264 rows x 64 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_df = pd.read_csv('data/world_bank_pops.csv')\n",
    "pop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>count</th>\n",
       "      <th>iso3</th>\n",
       "      <th>name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>6136862</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>326687501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GB</td>\n",
       "      <td>298758</td>\n",
       "      <td>GBR</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GBR</td>\n",
       "      <td>66460344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>260177</td>\n",
       "      <td>CAN</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CAN</td>\n",
       "      <td>37057765.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JP</td>\n",
       "      <td>259359</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JPN</td>\n",
       "      <td>126529100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR</td>\n",
       "      <td>250505</td>\n",
       "      <td>FRA</td>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "      <td>66977107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>SO</td>\n",
       "      <td>1</td>\n",
       "      <td>SOM</td>\n",
       "      <td>Somalia</td>\n",
       "      <td>SOM</td>\n",
       "      <td>15008154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>SX</td>\n",
       "      <td>1</td>\n",
       "      <td>SXM</td>\n",
       "      <td>Sint Maarten</td>\n",
       "      <td>SXM</td>\n",
       "      <td>40654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>TV</td>\n",
       "      <td>1</td>\n",
       "      <td>TUV</td>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>TUV</td>\n",
       "      <td>11508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>VC</td>\n",
       "      <td>1</td>\n",
       "      <td>VCT</td>\n",
       "      <td>St. Vincent and the Grenadines</td>\n",
       "      <td>VCT</td>\n",
       "      <td>110210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>XK</td>\n",
       "      <td>1</td>\n",
       "      <td>XKX</td>\n",
       "      <td>Kosovo</td>\n",
       "      <td>XKX</td>\n",
       "      <td>1845300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    term    count iso3                            name Country Code  \\\n",
       "0     US  6136862  USA                   United States          USA   \n",
       "1     GB   298758  GBR                  United Kingdom          GBR   \n",
       "2     CA   260177  CAN                          Canada          CAN   \n",
       "3     JP   259359  JPN                           Japan          JPN   \n",
       "4     FR   250505  FRA                          France          FRA   \n",
       "..   ...      ...  ...                             ...          ...   \n",
       "204   SO        1  SOM                         Somalia          SOM   \n",
       "205   SX        1  SXM                    Sint Maarten          SXM   \n",
       "206   TV        1  TUV                          Tuvalu          TUV   \n",
       "207   VC        1  VCT  St. Vincent and the Grenadines          VCT   \n",
       "208   XK        1  XKX                          Kosovo          XKX   \n",
       "\n",
       "            2018  \n",
       "0    326687501.0  \n",
       "1     66460344.0  \n",
       "2     37057765.0  \n",
       "3    126529100.0  \n",
       "4     66977107.0  \n",
       "..           ...  \n",
       "204   15008154.0  \n",
       "205      40654.0  \n",
       "206      11508.0  \n",
       "207     110210.0  \n",
       "208    1845300.0  \n",
       "\n",
       "[209 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_countries_pop_df = pd.merge(all_occur_countries_df, \n",
    "                                pop_df[['Country Code', '2018']], \n",
    "                                left_on='iso3', \n",
    "                                right_on='Country Code')\n",
    "all_countries_pop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AI',\n",
       " 'AN',\n",
       " 'AQ',\n",
       " 'AX',\n",
       " 'BL',\n",
       " 'BQ',\n",
       " 'CX',\n",
       " 'FK',\n",
       " 'FX',\n",
       " 'GF',\n",
       " 'GG',\n",
       " 'GP',\n",
       " 'IO',\n",
       " 'JE',\n",
       " 'MQ',\n",
       " 'PM',\n",
       " 'PN',\n",
       " 'QZ',\n",
       " 'RE',\n",
       " 'SH',\n",
       " 'TP',\n",
       " 'TW',\n",
       " 'UM',\n",
       " 'WF',\n",
       " 'YT',\n",
       " 'YU'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all_occur_countries_df['term'].values) - set(all_countries_pop_df['term'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We lost some countries in the join, but this is due to the more granular political reporting of the FDA data and, given this is just a data exploration, it isn't a concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.160503</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      2018\n",
       "count  1.000000  0.160503\n",
       "2018   0.160503  1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_countries_pop_df[['count', '2018']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, we see a very weak correlation, but this could reflect cultural and economic characteristics (the more dissimilar to the US, the less reporting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.493739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.493739</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      2018\n",
       "count  1.000000  0.493739\n",
       "2018   0.493739  1.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_countries_pop_df[~all_countries_pop_df['name'].isin(['China', 'India'])][['count', '2018']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure enough, we see outlier effects.\n",
    "\n",
    "Let's remove a few more large and \"different\" countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.52914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.52914</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count     2018\n",
       "count  1.00000  0.52914\n",
       "2018   0.52914  1.00000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_countries_pop_df[~all_countries_pop_df['name'].isin(['China', 'India', 'Bangladesh', 'Nigeria'])][['count', '2018']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it goes up some more.\n",
    "\n",
    "Now, let's trying using a more robust correlation method (without dropping any countries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.682119</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      2018\n",
       "count  1.000000  0.682119\n",
       "2018   0.682119  1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_countries_pop_df[['count', '2018']].corr(method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is the significance of this?  It just highlights an additional factor that impacts adverse event reporting across countries. **For this reason, an implementation will avoid relying on comparisons that rely on FAERS counts.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Examining Adverse Event Labeling\n",
    "\n",
    "For patient reactions, we do expect multiple rows with the same reaction. However, because these are (presumably) just human-entered form inputs, it would be good to have an understanding of how well the text data was standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patient_reactions_d = load_json_file('data/all_patient_reactions.json')\n",
    "all_patient_reactions_df = pd.DataFrame.from_dict(all_patient_reactions_d)\n",
    "all_patient_reactions_df['term'] = all_patient_reactions_df['term'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289                                 abasia\n",
       "64                    abdominal discomfort\n",
       "98                    abdominal distension\n",
       "29                          abdominal pain\n",
       "408                   abdominal pain lower\n",
       "42                    abdominal pain upper\n",
       "225                     abnormal behaviour\n",
       "325                        abnormal dreams\n",
       "565                   abnormal weight gain\n",
       "777                       abortion induced\n",
       "259                   abortion spontaneous\n",
       "649                                abscess\n",
       "830                               accident\n",
       "235         accidental exposure to product\n",
       "329                    accidental overdose\n",
       "152                                   acne\n",
       "353    activities of daily living impaired\n",
       "880                acute coronary syndrome\n",
       "734                  acute hepatic failure\n",
       "77                     acute kidney injury\n",
       "641                acute myeloid leukaemia\n",
       "326            acute myocardial infarction\n",
       "582    acute respiratory distress syndrome\n",
       "605              acute respiratory failure\n",
       "177                  adverse drug reaction\n",
       "111                          adverse event\n",
       "721                       adverse reaction\n",
       "785                        affect lability\n",
       "456                                ageusia\n",
       "191                             aggression\n",
       "126                              agitation\n",
       "600                        agranulocytosis\n",
       "662                              akathisia\n",
       "172     alanine aminotransferase increased\n",
       "43                                alopecia\n",
       "524         altered state of consciousness\n",
       "536                            amenorrhoea\n",
       "156                                amnesia\n",
       "41                                 anaemia\n",
       "234                  anaphylactic reaction\n",
       "448                     anaphylactic shock\n",
       "298                                  anger\n",
       "345                        angina pectoris\n",
       "960                        angina unstable\n",
       "264                             angioedema\n",
       "449                              anhedonia\n",
       "644                         ankle fracture\n",
       "482                               anorexia\n",
       "671                                anosmia\n",
       "859                                 anuria\n",
       "Name: term, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_patient_reactions_df['term'].sort_values()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, we can see that indices 408 (\"ABDOMINAL PAIN LOWER\") and 42 (\"ABDOMINAL PAIN UPPER\") are both types of 29 (\"ABDOMINAL PAIN\").  Thus, we know that the OpenFDA API does not have this kind of standardization.\n",
    "\n",
    "---\n",
    "### Deduplication\n",
    "\n",
    "Now, let's look at the bottom of the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68     wrong technique in product usage process\n",
       "190       wrong technique in drug usage process\n",
       "561     wrong technique in device usage process\n",
       "668                     wrong drug administered\n",
       "773                              wrist fracture\n",
       "968                             wound infection\n",
       "556                                       wound\n",
       "313                         withdrawal syndrome\n",
       "276            white blood cell count increased\n",
       "106            white blood cell count decreased\n",
       "249                                    wheezing\n",
       "32                             weight increased\n",
       "24                             weight decreased\n",
       "11                                     vomiting\n",
       "997                           vitreous floaters\n",
       "935                        vitamin d deficiency\n",
       "959                         vitamin d decreased\n",
       "94                            visual impairment\n",
       "980                         visual field defect\n",
       "878                          visual disturbance\n",
       "256                       visual acuity reduced\n",
       "71                               vision blurred\n",
       "355                             viral infection\n",
       "179                                     vertigo\n",
       "581                     ventricular tachycardia\n",
       "738                    ventricular fibrillation\n",
       "770                   ventricular extrasystoles\n",
       "806                                  vasculitis\n",
       "226                         vaginal haemorrhage\n",
       "776                           vaginal discharge\n",
       "922                                     uveitis\n",
       "798                         uterine perforation\n",
       "57                                    urticaria\n",
       "940                                   urosepsis\n",
       "868                      urine output decreased\n",
       "58                      urinary tract infection\n",
       "343                           urinary retention\n",
       "361                        urinary incontinence\n",
       "248           upper respiratory tract infection\n",
       "508                         upper limb fracture\n",
       "555          upper gastrointestinal haemorrhage\n",
       "410                     unresponsive to stimuli\n",
       "892        unintentional medical device removal\n",
       "789                        unintended pregnancy\n",
       "142                           unevaluable event\n",
       "163                                   underdose\n",
       "634                                       ulcer\n",
       "317                    type 2 diabetes mellitus\n",
       "577                tubulointerstitial nephritis\n",
       "740                                tuberculosis\n",
       "Name: term, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_patient_reactions_df['term'].sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row-pairs like 276-106 and 32-24 are very similar, but the last token makes these opposites (semantically speaking), so we would lose meaning by simply truncating the levels. However, if we calculate metrics on both the first and last tokens, then this may provide us with two conservative estimates of how many unique reaction events exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_reactions_series = all_patient_reactions_df['term'].str.split()\n",
    "first_tokens = split_reactions_series.apply(lambda x: x[0])\n",
    "last_tokens = split_reactions_series.apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           drug\n",
       "1         nausea\n",
       "2          death\n",
       "3        fatigue\n",
       "4       headache\n",
       "5      diarrhoea\n",
       "6       dyspnoea\n",
       "7           pain\n",
       "8            off\n",
       "9      dizziness\n",
       "10       malaise\n",
       "11      vomiting\n",
       "12          rash\n",
       "13      asthenia\n",
       "14    arthralgia\n",
       "Name: term, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_tokens[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     ineffective\n",
       "1          nausea\n",
       "2           death\n",
       "3         fatigue\n",
       "4        headache\n",
       "5       diarrhoea\n",
       "6        dyspnoea\n",
       "7            pain\n",
       "8             use\n",
       "9       dizziness\n",
       "10        malaise\n",
       "11       vomiting\n",
       "12           rash\n",
       "13       asthenia\n",
       "14     arthralgia\n",
       "Name: term, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_tokens[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_tokens_set = set(first_tokens)\n",
    "last_tokens_set = set(last_tokens)\n",
    "num_common = len(first_tokens_set & last_tokens_set)\n",
    "num_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5387045813586098"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_common/len(first_tokens_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6144144144144145"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_common/len(last_tokens_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that these will have limited efficacy, as many labels (from this example) are only a single token. Regardless, it still provides a naive summary baseline.\n",
    "\n",
    "Another step we can take is to remove English stop words. While we are at it, we will also remove any unordered, duplicate tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stop_words = stopwords.words('english')\n",
    "combined_hash_d = {}    # Frozenset dict to identify equal unordered patient reactions\n",
    "dropped_patient_reactions = set()    # Duplicated patient reactions to remove\n",
    "no_stop_words_patient_reactions = []    # Patient reactions without stop words\n",
    "\n",
    "for reaction in all_patient_reactions_df['term'].values:\n",
    "    no_stop_word_tokens = [token for token in reaction.split() if token not in en_stop_words]\n",
    "    tokenized_event = frozenset(no_stop_word_tokens)\n",
    "    if tokenized_event not in combined_hash_d:\n",
    "        combined_hash_d[tokenized_event] = 1\n",
    "        no_stop_words_patient_reactions.append(' '.join(no_stop_word_tokens))\n",
    "    else:\n",
    "        dropped_patient_reactions = dropped_patient_reactions | set([reaction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unforunately, it did not make much of a difference here. However, it may be useful when comparing the countries directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adverse event'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped_patient_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bcf4k\\.virtualenvs\\astrazeneca-xwrglwwk\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(999, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduped_reactions_df = all_patient_reactions_df[~all_patient_reactions_df['term'].isin(dropped_patient_reactions)]\n",
    "deduped_reactions_df.loc[:, 'term'] = no_stop_words_patient_reactions\n",
    "deduped_reactions_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional token metrics\n",
    "\n",
    "Since we have already tokenized the labels, let's go ahead and take a look at related metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = set()\n",
    "token_lens = []\n",
    "all_tokens = []\n",
    "for key in combined_hash_d.keys():\n",
    "    cur_tokens = [token for token in key]\n",
    "    token_lens.append(len(cur_tokens))\n",
    "    all_tokens += cur_tokens\n",
    "    tokens = tokens | set(cur_tokens)\n",
    "token_lens = np.array(token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('disorder', 40),\n",
       " ('increased', 38),\n",
       " ('decreased', 35),\n",
       " ('blood', 34),\n",
       " ('drug', 32),\n",
       " ('pain', 31),\n",
       " ('site', 26),\n",
       " ('product', 26),\n",
       " ('infection', 21),\n",
       " ('device', 20),\n",
       " ('injection', 17),\n",
       " ('abnormal', 17),\n",
       " ('haemorrhage', 17),\n",
       " ('skin', 16),\n",
       " ('syndrome', 16),\n",
       " ('failure', 14),\n",
       " ('disease', 14),\n",
       " ('injury', 13),\n",
       " ('respiratory', 12),\n",
       " ('fracture', 12),\n",
       " ('error', 11),\n",
       " ('rash', 10),\n",
       " ('discomfort', 10),\n",
       " ('renal', 10),\n",
       " ('pulmonary', 10),\n",
       " ('count', 10),\n",
       " ('issue', 9),\n",
       " ('administered', 9),\n",
       " ('acute', 9),\n",
       " ('reaction', 9),\n",
       " ('eye', 9),\n",
       " ('muscle', 8),\n",
       " ('oedema', 8),\n",
       " ('swelling', 8),\n",
       " ('cell', 7)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_counter = Counter(all_tokens)\n",
    "tokens_counter.most_common(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these seem like fairly generic medical words and with a deeper examination could become domain-specific stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    999.000000\n",
       "mean       2.036036\n",
       "std        0.894597\n",
       "min        1.000000\n",
       "25%        1.000000\n",
       "50%        2.000000\n",
       "75%        3.000000\n",
       "max        6.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(token_lens).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This just confirms that the labels are just a few tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "963"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we have fewer unique tokens than there are events, so it is a limited vocabulary (but very domain-specific)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fastText Embedding Approach\n",
    "\n",
    "Let's see if there is anything we can do with these events using a domain-specific fastText embedding (https://github.com/ncbi-nlp/BioSentVec#biowordvec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "bioword_m = fasttext.load_model('models/BioWordVec_PubMed_MIMICIII_d200.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well the embeddings model works first.  \n",
    "\n",
    "We'll begin by examining performance on individual tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(963, 200)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_vectors = np.array([bioword_m[token] for token in tokens])\n",
    "token_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the `sklearn.neighbors.NearestNeighbors` implementation, we need to define a cosine metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    return distance.cosine(x, y)\n",
    "cosine_dist = DistanceMetric.get_metric(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(metric=<function cosine_similarity at 0x000001260CA67B88>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NearestNeighbors(metric=cosine_similarity)\n",
    "nn.fit(token_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we are only using a data split because we are not trying to perform an inference operation.\n",
    "\n",
    "Let's make a few helper functions to help view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_lookup = list(tokens)\n",
    "\n",
    "def get_token(index, lookup):\n",
    "    return lookup[index]\n",
    "\n",
    "def get_vector(index, vectors):\n",
    "    return vectors[index].reshape(1,-1)\n",
    "\n",
    "def query_nn(q_token, lookup, vectors, n=10):\n",
    "    dists, indices = nn.kneighbors(get_vector(lookup.index(q_token), vectors), \n",
    "                                   n_neighbors=n)\n",
    "    nn_tokens = []\n",
    "    for index in indices[0]:\n",
    "        nn_tokens.append(get_token(index, lookup))\n",
    "    nn_df = pd.DataFrame()\n",
    "    nn_df['tokens'] = nn_tokens\n",
    "    nn_df['dists'] = dists[0]\n",
    "    return nn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>dists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardiovascular</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cerebrovascular</td>\n",
       "      <td>0.267182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardiac</td>\n",
       "      <td>0.328129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heart</td>\n",
       "      <td>0.332133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardio-respiratory</td>\n",
       "      <td>0.333668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hypertension</td>\n",
       "      <td>0.353343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>coronary</td>\n",
       "      <td>0.374313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>obesity</td>\n",
       "      <td>0.388123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hypertensive</td>\n",
       "      <td>0.397763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>arteriosclerosis</td>\n",
       "      <td>0.412435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tokens     dists\n",
       "0      cardiovascular  0.000000\n",
       "1     cerebrovascular  0.267182\n",
       "2             cardiac  0.328129\n",
       "3               heart  0.332133\n",
       "4  cardio-respiratory  0.333668\n",
       "5        hypertension  0.353343\n",
       "6            coronary  0.374313\n",
       "7             obesity  0.388123\n",
       "8        hypertensive  0.397763\n",
       "9    arteriosclerosis  0.412435"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_nn('cardiovascular', tokens_lookup, token_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>dists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>renal</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kidney</td>\n",
       "      <td>0.168924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nephropathy</td>\n",
       "      <td>0.309620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tubulointerstitial</td>\n",
       "      <td>0.313288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glomerular</td>\n",
       "      <td>0.313915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nephrolithiasis</td>\n",
       "      <td>0.318619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>anuria</td>\n",
       "      <td>0.327387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tubular</td>\n",
       "      <td>0.332714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>proteinuria</td>\n",
       "      <td>0.342649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pyelonephritis</td>\n",
       "      <td>0.364901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tokens     dists\n",
       "0               renal  0.000000\n",
       "1              kidney  0.168924\n",
       "2         nephropathy  0.309620\n",
       "3  tubulointerstitial  0.313288\n",
       "4          glomerular  0.313915\n",
       "5     nephrolithiasis  0.318619\n",
       "6              anuria  0.327387\n",
       "7             tubular  0.332714\n",
       "8         proteinuria  0.342649\n",
       "9      pyelonephritis  0.364901"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_nn('renal', tokens_lookup, token_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>dists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disease</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crohn's</td>\n",
       "      <td>0.406441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>progression</td>\n",
       "      <td>0.412011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sclerosis</td>\n",
       "      <td>0.426895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ulcerative</td>\n",
       "      <td>0.428422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>illness</td>\n",
       "      <td>0.428868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vasculitis</td>\n",
       "      <td>0.437415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arteriosclerosis</td>\n",
       "      <td>0.438886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arthropathy</td>\n",
       "      <td>0.454075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>progressive</td>\n",
       "      <td>0.460800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tokens     dists\n",
       "0           disease  0.000000\n",
       "1           crohn's  0.406441\n",
       "2       progression  0.412011\n",
       "3         sclerosis  0.426895\n",
       "4        ulcerative  0.428422\n",
       "5           illness  0.428868\n",
       "6        vasculitis  0.437415\n",
       "7  arteriosclerosis  0.438886\n",
       "8       arthropathy  0.454075\n",
       "9       progressive  0.460800"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_nn('disease', tokens_lookup, token_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>dists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>increased</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decreased</td>\n",
       "      <td>0.050103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reduced</td>\n",
       "      <td>0.134189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lower</td>\n",
       "      <td>0.300187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>altered</td>\n",
       "      <td>0.302783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>improved</td>\n",
       "      <td>0.328971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>impaired</td>\n",
       "      <td>0.376512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>associated</td>\n",
       "      <td>0.391276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aggravated</td>\n",
       "      <td>0.395201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>change</td>\n",
       "      <td>0.406824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tokens     dists\n",
       "0   increased  0.000000\n",
       "1   decreased  0.050103\n",
       "2     reduced  0.134189\n",
       "3       lower  0.300187\n",
       "4     altered  0.302783\n",
       "5    improved  0.328971\n",
       "6    impaired  0.376512\n",
       "7  associated  0.391276\n",
       "8  aggravated  0.395201\n",
       "9      change  0.406824"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_nn('increased', tokens_lookup, token_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>dists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abdominal</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chest</td>\n",
       "      <td>0.313670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pelvic</td>\n",
       "      <td>0.331445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distension</td>\n",
       "      <td>0.356398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hernia</td>\n",
       "      <td>0.357802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ileus</td>\n",
       "      <td>0.384067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>appendicitis</td>\n",
       "      <td>0.394053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bowel</td>\n",
       "      <td>0.401358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neck</td>\n",
       "      <td>0.402837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>groin</td>\n",
       "      <td>0.413477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tokens     dists\n",
       "0     abdominal  0.000000\n",
       "1         chest  0.313670\n",
       "2        pelvic  0.331445\n",
       "3    distension  0.356398\n",
       "4        hernia  0.357802\n",
       "5         ileus  0.384067\n",
       "6  appendicitis  0.394053\n",
       "7         bowel  0.401358\n",
       "8          neck  0.402837\n",
       "9         groin  0.413477"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_nn('abdominal', tokens_lookup, token_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These latter three embeddings are not bad, but they do demonstrate some potentially troubling characteristics. For example, it's not ideal (euphemestically) for \"increased\" and \"decreased\" to be _so_ close.\n",
    "\n",
    "Okay, well now let's take a look at an embedding for a whole phrase.  Because the model is meant for tokens, we don't want to embed the whole event label. Instead, we will get the average embedding for the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_embed(label):\n",
    "    tokens = label.split()\n",
    "    num_tokens = len(tokens)\n",
    "    embed = np.zeros((1,200))\n",
    "    for token in tokens:\n",
    "        embed += bioword_m[token].reshape(1,-1)\n",
    "    return embed/num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_embeds = []\n",
    "for reaction in deduped_reactions_df['term'].values:\n",
    "    avg_embeds.append(calc_avg_embed(reaction))\n",
    "avg_embeds = np.array(avg_embeds).reshape(deduped_reactions_df.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(metric=<function cosine_similarity at 0x000001260CA67B88>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NearestNeighbors(metric=cosine_similarity)\n",
    "nn.fit(avg_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>dists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acute kidney injury</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>renal injury</td>\n",
       "      <td>0.080062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>renal failure acute</td>\n",
       "      <td>0.134533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>liver injury</td>\n",
       "      <td>0.145278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drug-induced liver injury</td>\n",
       "      <td>0.162303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>injury</td>\n",
       "      <td>0.175621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chronic kidney disease</td>\n",
       "      <td>0.178010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>renal failure chronic</td>\n",
       "      <td>0.178440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acute hepatic failure</td>\n",
       "      <td>0.179313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>brain injury</td>\n",
       "      <td>0.192022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      tokens     dists\n",
       "0        acute kidney injury  0.000000\n",
       "1               renal injury  0.080062\n",
       "2        renal failure acute  0.134533\n",
       "3               liver injury  0.145278\n",
       "4  drug-induced liver injury  0.162303\n",
       "5                     injury  0.175621\n",
       "6     chronic kidney disease  0.178010\n",
       "7      renal failure chronic  0.178440\n",
       "8      acute hepatic failure  0.179313\n",
       "9               brain injury  0.192022"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_nn('acute kidney injury', no_stop_words_patient_reactions, avg_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>dists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alanine aminotransferase increased</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aspartate aminotransferase increased</td>\n",
       "      <td>0.023540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transaminases increased</td>\n",
       "      <td>0.120841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gamma-glutamyltransferase increased</td>\n",
       "      <td>0.155268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blood lactate dehydrogenase increased</td>\n",
       "      <td>0.248330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blood creatine phosphokinase increased</td>\n",
       "      <td>0.248375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hepatic enzyme increased</td>\n",
       "      <td>0.265477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>blood alkaline phosphatase increased</td>\n",
       "      <td>0.278147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lipase increased</td>\n",
       "      <td>0.302263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blood creatinine increased</td>\n",
       "      <td>0.308782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tokens     dists\n",
       "0      alanine aminotransferase increased  0.000000\n",
       "1    aspartate aminotransferase increased  0.023540\n",
       "2                 transaminases increased  0.120841\n",
       "3     gamma-glutamyltransferase increased  0.155268\n",
       "4   blood lactate dehydrogenase increased  0.248330\n",
       "5  blood creatine phosphokinase increased  0.248375\n",
       "6                hepatic enzyme increased  0.265477\n",
       "7    blood alkaline phosphatase increased  0.278147\n",
       "8                        lipase increased  0.302263\n",
       "9              blood creatinine increased  0.308782"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_nn('alanine aminotransferase increased', no_stop_words_patient_reactions, avg_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>dists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vaginal haemorrhage</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>genital haemorrhage</td>\n",
       "      <td>0.101093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rectal haemorrhage</td>\n",
       "      <td>0.138552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uterine perforation</td>\n",
       "      <td>0.192724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haemorrhage</td>\n",
       "      <td>0.200422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gastrointestinal haemorrhage</td>\n",
       "      <td>0.209894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gastric haemorrhage</td>\n",
       "      <td>0.221301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vaginal discharge</td>\n",
       "      <td>0.222550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>skin haemorrhage</td>\n",
       "      <td>0.229548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>haemorrhage intracranial</td>\n",
       "      <td>0.246088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         tokens     dists\n",
       "0           vaginal haemorrhage  0.000000\n",
       "1           genital haemorrhage  0.101093\n",
       "2            rectal haemorrhage  0.138552\n",
       "3           uterine perforation  0.192724\n",
       "4                   haemorrhage  0.200422\n",
       "5  gastrointestinal haemorrhage  0.209894\n",
       "6           gastric haemorrhage  0.221301\n",
       "7             vaginal discharge  0.222550\n",
       "8              skin haemorrhage  0.229548\n",
       "9      haemorrhage intracranial  0.246088"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_nn('vaginal haemorrhage', no_stop_words_patient_reactions, avg_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good as well.\n",
    "\n",
    "With this information in mind, let's move to a solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
